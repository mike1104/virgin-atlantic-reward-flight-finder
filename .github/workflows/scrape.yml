name: Scrape

on:
  schedule:
    - cron: "0 */3 * * *" # Every 3 hours
  workflow_dispatch: # Manual trigger

permissions:
  contents: read
  actions: write
  pages: write
  id-token: write

concurrency:
  group: pages
  cancel-in-progress: false

jobs:
  scrape-and-deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: npm

      - run: npm ci

      - name: Compile TypeScript
        run: npx tsc

      - name: Install Playwright Chromium
        run: npx playwright install --with-deps chromium

      - name: Scrape, process, and build
        run: node dist/cli.js all
        env:
          VA_REQUEST_MAX_IN_FLIGHT: "8"
          VA_REQUEST_DISPATCH_INTERVAL_MS: "100"
          VA_REQUEST_DISPATCH_INTERVAL_JITTER_MS: "10"

      - name: Upload scraped data artifact
        uses: actions/upload-artifact@v4
        with:
          name: scraped-data
          retention-days: 90
          path: |
            output/flights-data.json
            output/destinations.json
            output/scrape-metadata.json

      - name: Upload Pages artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: output

  deploy:
    needs: scrape-and-deploy
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
